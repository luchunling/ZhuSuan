#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
import sys
import os
import time

import tensorflow as tf
from tensorflow.contrib import layers
from tensorflow.python.ops import init_ops
from six.moves import range
import numpy as np

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import zhusuan as zs

import dataset
import utils
import multi_gpu
from multi_gpu import FLAGS
import pdb


def lrelu(input_tensor, leak=0.1, name="lrelu"):
    with tf.variable_scope(name):
        f1 = 0.5 * (1 + leak)
        f2 = 0.5 * (1 - leak)
        return f1 * input_tensor + f2 * abs(input_tensor)


def max_out(input_tensor, num_pieces=2):
    shape = input_tensor.get_shape()
    output = tf.reshape(input_tensor, [-1, int(shape[1]), int(shape[2]),
                                       int(shape[3]) // num_pieces, num_pieces])
    output = tf.reduce_max(output, axis=-1)
    return output


def ali(classifier, encoder, decoder):
    """
    Implements the Adversarial Learned Inference (ALI) algorithm.

    :param classifier: A function that accepts a Tensor. The function should
        return a Tensor, representing the unnormalized log probability that
        the input is real instead of being generated by decoder.
    :param encoder: A dict of (str, Tenosr) mapping from 'x' and 'z' to their
        corresponding value.
    :param decoder: A dict of (str, Tenosr) mapping from 'x' and 'z' to their
        corresponding value.

    :return disc_loss: A Tensor. The loss to be minimized by discriminator.
    :return gen_loss: A Tensor. The loss to be minimized by generator.
    """
    enc_class_logits = classifier(encoder['x'], encoder['z'])
    dec_class_logits = classifier(decoder['x'], decoder['z'])

    disc_loss_list = [tf.reduce_mean(
        tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.ones_like(enc_class_logits),
            logits=enc_class_logits)),
        tf.reduce_mean(
            tf.nn.sigmoid_cross_entropy_with_logits(
                labels=tf.zeros_like(dec_class_logits),
                logits=dec_class_logits))]
    disc_loss = sum(disc_loss_list)
    gen_loss_list = [tf.reduce_mean(
        tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.zeros_like(enc_class_logits),
            logits=enc_class_logits)),
        tf.reduce_mean(
            tf.nn.sigmoid_cross_entropy_with_logits(
                labels=tf.ones_like(dec_class_logits),
                logits=dec_class_logits))]
    gen_loss = sum(gen_loss_list)
    return disc_loss, gen_loss, disc_loss_list, gen_loss_list


@zs.reuse('decoder')
def decoder(observed, n, n_z=64, is_training=True):
    with zs.StochasticGraph(observed=observed) as decoder:
        normalizer_params = {'is_training': is_training,
                             'updates_collections': None}

        z_mean = tf.zeros([n_z])
        z_logstd = tf.zeros([n_z])
        z = zs.Normal('z', z_mean, z_logstd, sample_dim=0, n_samples=n)
        lx_z = tf.reshape(z, [-1, 1, 1, n_z])
        lx_z = layers.conv2d_transpose(lx_z, 256, 4, 1, activation_fn=lrelu,
                                       padding='VALID', weights_initializer=
                                       init_ops.RandomNormal(stddev=0.01),
                                       normalizer_fn=layers.batch_norm,
                                       normalizer_params=normalizer_params)

        lx_z = layers.conv2d_transpose(lx_z, 128, 4, stride=2,
                                       padding='VALID', weights_initializer=
                                       init_ops.RandomNormal(stddev=0.01),
                                       activation_fn=lrelu,
                                       normalizer_fn=layers.batch_norm,
                                       normalizer_params=normalizer_params)
        lx_z = layers.conv2d_transpose(lx_z, 64, 4, stride=1,
                                       padding='VALID', weights_initializer=
                                       init_ops.RandomNormal(stddev=0.01),
                                       activation_fn=lrelu,
                                       normalizer_fn=layers.batch_norm,
                                       normalizer_params=normalizer_params)
        lx_z = layers.conv2d_transpose(lx_z, 32, 4, stride=2,
                                       padding='VALID', weights_initializer=
                                       init_ops.RandomNormal(stddev=0.01),
                                       activation_fn=lrelu,
                                       normalizer_fn=layers.batch_norm,
                                       normalizer_params=normalizer_params)
        lx_z = layers.conv2d_transpose(lx_z, 32, 5, stride=1,
                                       padding='VALID', weights_initializer=
                                       init_ops.RandomNormal(stddev=0.01),
                                       activation_fn=lrelu,
                                       normalizer_fn=layers.batch_norm,
                                       normalizer_params=normalizer_params)
        lx_z = layers.conv2d(lx_z, 32, 1, stride=1, activation_fn=lrelu,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01),
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params)
        lx_z = layers.conv2d(lx_z, 3, 1, stride=1, activation_fn=tf.nn.sigmoid,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))

    return decoder, lx_z, z


@zs.reuse('encoder')
def encoder(observed, x, n_z, is_training):
    with zs.StochasticGraph(observed=observed) as encoder:
        normalizer_params = {'is_training': is_training,
                             'updates_collections': None}
        lz_x = layers.conv2d(x, 32, 5, stride=1, activation_fn=lrelu,
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        lz_x = layers.conv2d(lz_x, 64, 4, stride=2, activation_fn=lrelu,
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        lz_x = layers.conv2d(lz_x, 128, 4, stride=1, activation_fn=lrelu,
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        lz_x = layers.conv2d(lz_x, 256, 4, stride=2, activation_fn=lrelu,
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        lz_x = layers.conv2d(lz_x, 512, 4, stride=1, activation_fn=lrelu,
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        lz_x = layers.conv2d(lz_x, 512, 1, stride=1, activation_fn=lrelu,
                             padding='VALID', normalizer_fn=layers.batch_norm,
                             normalizer_params=normalizer_params,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        lz_x = layers.conv2d(lz_x, 128, 1, stride=1, activation_fn=None,
                             weights_initializer=
                             init_ops.RandomNormal(stddev=0.01))
        mu, logstd = lz_x[:, :, :, :n_z], lz_x[:, :, :, n_z:]
        lz_x = zs.Normal('z', mu, logstd)
    return encoder, lz_x


@zs.reuse('discriminator')
def discriminator(x, z, is_training):
    num_pieces = 2
    lc_x = max_out(layers.conv2d(
        layers.dropout(x, 0.8, is_training=is_training),
        32, 5, padding='VALID', activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_x = max_out(layers.conv2d(
        layers.dropout(lc_x, 0.5, is_training=is_training),
        64, 4, stride=2, padding='VALID', activation_fn=None,
        weights_initializer=init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_x = max_out(layers.conv2d(
        layers.dropout(lc_x, 0.5, is_training=is_training),
        128, 4, padding='VALID', activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_x = max_out(layers.conv2d(
        layers.dropout(lc_x, 0.5, is_training=is_training),
        256, 4, stride=2, padding='VALID', activation_fn=None,
        weights_initializer=init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_x = max_out(layers.conv2d(
        layers.dropout(lc_x, 0.5, is_training=is_training),
        512, 4, padding='VALID', activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)

    z = tf.reshape(z, [-1, 1, 1, n_z])
    lc_z = max_out(layers.conv2d(
        layers.dropout(z, 0.8, is_training=is_training),
        512, 1, activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_z = max_out(layers.conv2d(
        layers.dropout(lc_z, 0.5, is_training=is_training),
        512, 1, activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)

    lc_xz = tf.concat([lc_x, lc_z], -1)
    lc_xz = max_out(layers.conv2d(
        layers.dropout(lc_xz, 0.5, is_training=is_training),
        1024, 1, activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_xz = max_out(layers.conv2d(
        layers.dropout(lc_xz, 0.5, is_training=is_training),
        1024, 1, activation_fn=None, weights_initializer=
        init_ops.RandomNormal(stddev=0.01)), num_pieces)
    lc_xz = layers.flatten(lc_xz)
    lc_xz = layers.dropout(lc_xz, 0.5, is_training=is_training)
    class_logits = layers.fully_connected(lc_xz, 1, activation_fn=None,
                                          weights_initializer=
                                          init_ops.RandomNormal(stddev=0.01))
    return class_logits


if __name__ == "__main__":
    tf.set_random_seed(1234)

    # Load CIFAR
    data_path = os.path.join("/home/yucen/mfs/code/ZhuSuan/examples",
                             'data', 'cifar10', 'cifar-10-python.tar.gz')
    np.random.seed(1234)
    x_train, t_train, x_test, t_test = \
        dataset.load_cifar10(data_path, normalize=True, one_hot=True)
    _, n_xl, _, n_channels = x_train.shape
    n_y = t_train.shape[1]

    # Define model parameters
    n_z = 64

    # Define training/evaluation parameters
    lb_samples = 1
    epoches = 5000
    batch_size = 100 * FLAGS.num_gpus
    gen_size = 100
    recon_size = 50
    iters = x_train.shape[0] // batch_size
    print_freq = 100
    test_freq = iters
    save_freq = iters
    learning_rate = 0.0001
    anneal_lr_freq = 200
    anneal_lr_rate = 0.75

    result_path = os.environ['MODEL_RESULT_PATH_AND_PREFIX']

    # Build the computation graph
    is_training = tf.placeholder(tf.bool, shape=[], name='is_training')
    x = tf.placeholder(tf.float32, shape=(None, n_xl, n_xl, n_channels),
                       name='x')
    learning_rate_ph = tf.placeholder(tf.float32, shape=[], name='lr')
    optimizer = tf.train.AdamOptimizer(learning_rate_ph, beta1=0.5)

    n = tf.shape(x)[0]
    _, x_gen, z_prior = decoder(None, n, n_z, is_training)
    _, z_gen = encoder(None, x, n_z, is_training)

    classifier = lambda tmp_x, tmp_z: discriminator(tmp_x, tmp_z,
                                                    is_training)
    disc_loss, gen_loss, disc_loss_list, gen_loss_list = \
        ali(classifier,
            encoder={'x': x, 'z': z_gen},
            decoder={'x': x_gen, 'z': z_prior})

    dec_var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,
                                     scope='decoder')
    enc_var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,
                                     scope='encoder')
    disc_var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,
                                      scope='discriminator')
    gen_var_list = dec_var_list + enc_var_list

    disc_grads = optimizer.compute_gradients(disc_loss,
                                             var_list=disc_var_list)
    gen_grads = optimizer.compute_gradients(gen_loss,
                                            var_list=gen_var_list)
    grads = disc_grads + gen_grads
    infer = optimizer.apply_gradients(grads)

    def check_grads(loss, var_list):
        grads_to_be_check = optimizer.compute_gradients(loss, var_list=var_list)
        grads_to_be_check_ = [g for g, v in grads_to_be_check if g is not None]
        grads_to_be_check_mean = tf.reduce_mean(
            tf.stack([tf.reduce_mean(tf.square(g)) for g in grads_to_be_check_]))
        grads_to_be_check_var = tf.reduce_mean(
            tf.stack([tf.nn.moments(g, list(range(0, g.get_shape().ndims)))[1]
                      for g in grads_to_be_check_]))
        return grads_to_be_check_mean, grads_to_be_check_var


    check_px_grads = check_grads(gen_loss, var_list=dec_var_list)
    check_qzx_grads = check_grads(gen_loss, var_list=enc_var_list)

    check_list = []
    check_list += check_px_grads + check_qzx_grads

    # eval generation
    _, eval_x_gen, _ = decoder(None, gen_size, n_z, is_training)
    # eval reconstruction
    _, eval_z_gen = encoder(None, x, n_z, is_training)
    _, eval_x_recon, _ = decoder({'z': eval_z_gen},
                                 tf.shape(x)[0], n_z, is_training)

    params = tf.trainable_variables()
    for i in params:
        print(i.name, i.get_shape())

    var_list = gen_var_list + disc_var_list

    saver = tf.train.Saver(max_to_keep=10, var_list=var_list)
    # Run the inference
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range(1, epoches + 1):
            if epoch % anneal_lr_freq == 0:
                learning_rate *= anneal_lr_rate
            np.random.shuffle(x_train)
            fetches = []
            time_train = -time.time()
            for t in range(iters):
                itr = t + 1
                x_batch = x_train[t * batch_size:(t + 1) * batch_size]
                ft = sess.run(
                    [infer, gen_loss, disc_loss] + check_list,
                    feed_dict={x: x_batch,
                               learning_rate_ph: learning_rate,
                               is_training: True})
                fetches.append(ft[1:])

                if itr % print_freq == 0:
                    pt_fetches = np.mean(fetches, axis=0)
                    print('Epoch={} Iter={} ({:.3f}s/iter): '
                          'Gen loss = {} Disc loss = {}'
                          'Check px Grads, Mean = {}, Var = {}\n'
                          'Check qz_x Grads, Mean = {}, Var = {}\n'.
                          format(epoch, itr,
                                 (time.time() + time_train) / print_freq,
                                 *pt_fetches))
                    fetches = []

                if itr % test_freq == 0:
                    time_test = -time.time()
                    gen_images = sess.run(eval_x_gen,
                                          feed_dict={is_training: False})
                    name = "gen/ali.epoch.{}.iter.{}.png".format(epoch, itr)
                    name = os.path.join(result_path, name)
                    utils.save_image_collections(gen_images, name,
                                                 scale_each=True)

                    x_batch = x_test[:recon_size]
                    eval_zs, recon_images = \
                        sess.run([eval_z_gen.tensor, eval_x_recon],
                                 feed_dict={x: x_batch, is_training: False})
                    name = "recon/ali.epoch.{}.iter.{}.png".format(
                        epoch, itr)
                    name = os.path.join(result_path, name)
                    utils.save_contrast_image_collections(x_batch, recon_images,
                                                          name, scale_each=True)
                    time_test += time.time()

                if itr % save_freq == 0:
                    save_path = "ali.epoch.{}.iter.{}.ckpt".format(epoch, itr)
                    save_path = os.path.join(result_path, save_path)
                    saver.save(sess, save_path)

                if itr % print_freq == 0:
                    time_train = -time.time()

